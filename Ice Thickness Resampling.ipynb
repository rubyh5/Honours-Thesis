{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c595a1dc-450b-40cf-96c2-1ca1464b0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # used for numeric calculations and arrays\n",
    "from scipy.interpolate import griddata # used for interpolating onto a grid\n",
    "import netCDF4 as nc # used to open NetCDF4 files\n",
    "from netCDF4 import Dataset # used to open NetCDF4 files\n",
    "import os # used to communicate with operating system\n",
    "import re # used to search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff29f4-2eab-4c7a-9209-509bd389432f",
   "metadata": {},
   "source": [
    "# Output Longitude and Latitude (to interpolate onto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd745fa-b391-48fe-bacb-a6cdb10598b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:/Users/rubym/OneDrive - Australian National University/Honours/Sea Level Ice Outputs/Outputs (copied across)/9 Sept/'\n",
    "longlat = np.loadtxt(f'{folder}longlat') # load in the longitude and latitude grid that I want my data to match\n",
    "\n",
    "long = longlat[:, 0] # set longitude column\n",
    "lat = longlat[:, 1] # set latitude column\n",
    "longlat = np.array([long, lat]).T # transpose an array of long and lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171716ac-f3ea-4ee5-823e-41dbd1724031",
   "metadata": {},
   "source": [
    "# Ice 6G 122Ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2353196c-de47-420a-9701-258ad3d67a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'C:/Users/rubym/OneDrive - Australian National University/Honours/Python Drafts/Non-Interpolated Ice Histories/ICE-6G_C_122Ka' \n",
    "\n",
    "file_list = sorted(\n",
    "    [f for f in os.listdir(folder_path) if f.startswith(\"ice_thickness_\") and f.endswith(\".grd\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0]) if x.split('_')[-1].split('.')[0].isdigit() else float('inf'),\n",
    "    reverse=True)\n",
    "\n",
    "# identify and sort all files in the folder that start with \"ice_thickness_\" and end with \".grd\"\n",
    "\n",
    "counter = 1\n",
    "times_list = [] # store the time extracted from each file\n",
    "\n",
    "output_folder_path = 'C:/Users/rubym/OneDrive - Australian National University/Honours/Python Drafts/Interpolated Ice Histories/ICE-6G-122ka'\n",
    "\n",
    "for file_name in file_list: # loop through all ice thickness files in the folder\n",
    "    file_path = os.path.join(folder_path, file_name) # create filepaths that match the file names in the folder\n",
    "    \n",
    "    ice_data = Dataset(file_path) # open the files (NetCDF4)\n",
    "\n",
    "    time = int(file_name.split('_')[-1].split('.')[0]) # extracts the numeric portion of the filename used as a time index and store it in a list\n",
    "    times_list.append(time)\n",
    "\n",
    "    ice_lat = ice_data['lat'][:] # set latitude column\n",
    "    ice_lon = ice_data['lon'][:] # set longitude column\n",
    "    ice_thick = ice_data['stgit'][:] # set ice thickness column\n",
    "    \n",
    "    ice_lon = np.where(ice_lon > 180, ice_lon - 360, ice_lon) # convert longitude from [0, 360] range to [-180, 180] to match other data\n",
    "    \n",
    "    lon_grid, lat_grid = np.meshgrid(ice_lon, ice_lat) # create a 2D grid of existing data points \n",
    "    points = np.array([lon_grid.flatten(), lat_grid.flatten()]).T # flatten grid into 1D arrays\n",
    "    values = ice_thick.flatten() # flatten ice thickness into 1D array\n",
    "    grid_icethick_linear = griddata(points, values, longlat, method='linear') # linearly interpolate ice thickness points onto the long lat grid from above\n",
    "\n",
    "    nan_indices = np.isnan(grid_icethick_linear) # look for NaN values\n",
    "    if np.any(nan_indices): # if there are any NaN values\n",
    "       grid_icethick_nearest = griddata(points, values, longlat[nan_indices], method='nearest') # interpolate those values using the nearest point\n",
    "       grid_icethick_linear[nan_indices] = grid_icethick_nearest\n",
    "\n",
    "    output_file_path = os.path.join(output_folder_path, f'ice{counter}') # save the nterpolated ice thickness data to a file with a time index\n",
    "    np.savetxt(output_file_path, grid_icethick_linear)\n",
    "  \n",
    "    counter += 1 # increase the counter so that the next file is named differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a285951e-ac86-4181-b769-bbb6286d9527",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_array = np.array(times_list) # turn the list of times into an array\n",
    "times_array = -times_array # set the times to poisitive\n",
    "\n",
    "times_file_path = os.path.join(output_folder_path, 'times') # save the times array\n",
    "np.savetxt(times_file_path, times_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c0ed2-9e67-4737-8f37-0cd3aa4b9053",
   "metadata": {},
   "source": [
    "# Ice 6G 26Ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c6349c-f501-4a92-9ebd-c06d0c3e479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same method as above\n",
    "\n",
    "folder_path = 'C:/Users/rubym/OneDrive - Australian National University/Honours/Python Drafts/Non-Interpolated Ice Histories/ICE-6G_C_26Ka'\n",
    "\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'I6_C\\.VM5a_1deg\\.(\\d+(\\.\\d+)?)', filename)\n",
    "    if match:\n",
    "         return float(match.group(1))\n",
    "\n",
    "file_list = sorted(\n",
    "    [f for f in os.listdir(folder_path) if f.startswith(\"I6_C.VM5a_1deg.\") and f.endswith(\".nc\")],\n",
    "    key=extract_number,\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "counter = 1\n",
    "times_list = []\n",
    "\n",
    "output_folder_path = 'C:/Users/rubym/OneDrive - Australian National University/Honours/Python Drafts/Interpolated Ice Histories/ICE-6G-26ka'\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    ice_data = Dataset(file_path)\n",
    "\n",
    "    time = file_name.split('_1deg.')[-1].split('.nc')[0]\n",
    "    \n",
    "    times_list.append(time)\n",
    "\n",
    "    ice_lat = ice_data['lat'][:]\n",
    "    ice_lon = ice_data['lon'][:]\n",
    "    ice_thick = ice_data['stgit'][:]\n",
    "    \n",
    "    ice_lon = np.where(ice_lon > 180, ice_lon - 360, ice_lon)\n",
    "    \n",
    "    lon_grid, lat_grid = np.meshgrid(ice_lon, ice_lat)\n",
    "    points = np.array([lon_grid.flatten(), lat_grid.flatten()]).T\n",
    "    values = ice_thick.flatten()\n",
    "    grid_icethick_linear = griddata(points, values, longlat, method='linear')\n",
    "\n",
    "    nan_indices = np.isnan(grid_icethick_linear)\n",
    "    if np.any(nan_indices):\n",
    "      grid_icethick_nearest = griddata(points, values, longlat[nan_indices], method='nearest')\n",
    "      grid_icethick_linear[nan_indices] = grid_icethick_nearest\n",
    "\n",
    "    output_file_path = os.path.join(output_folder_path, f'ice{counter}')  # No extension\n",
    "    np.savetxt(output_file_path, grid_icethick_linear)\n",
    "  \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90561a28-39d5-4281-8274-71390b5e6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same method as above\n",
    "\n",
    "times_array = np.array(times_list, dtype=float)\n",
    "times_array = -times_array * 1000\n",
    "\n",
    "times_file_path = os.path.join(output_folder_path, 'times')\n",
    "np.savetxt(times_file_path, times_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd63507-046f-489c-85e3-73229544e0f1",
   "metadata": {},
   "source": [
    "# Ice 7G 26Ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4eb88a-8a90-4ddb-a715-0fe92a2fbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same method as above\n",
    "\n",
    "folder_path = 'C:/Users/rubym/OneDrive - Australian National University/Honours/Python Drafts/Non-Interpolated Ice Histories/ICE-7G_NA_26Ka'\n",
    "\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'I7G_NA\\.VM7_1deg\\.(\\d+(\\.\\d+)?)', filename)\n",
    "    if match:\n",
    "         return float(match.group(1))\n",
    "\n",
    "file_list = sorted(\n",
    "    [f for f in os.listdir(folder_path) if f.startswith(\"I7G_NA.VM7_1deg.\") and f.endswith(\".nc\")],\n",
    "    key=extract_number,\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "counter = 1\n",
    "times_list = []\n",
    "\n",
    "output_folder_path = 'C:/Users/rubym/OneDrive - Australian National University/Honours/Python Drafts/Interpolated Ice Histories/ICE-7G'\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    ice_data = Dataset(file_path)\n",
    "\n",
    "    time = file_name.split('_1deg.')[-1].split('.nc')[0]\n",
    "    \n",
    "    times_list.append(time)\n",
    "\n",
    "    ice_lat = ice_data['lat'][:]\n",
    "    ice_lon = ice_data['lon'][:]\n",
    "    ice_thick = ice_data['stgit'][:]\n",
    "    \n",
    "    ice_lon = np.where(ice_lon > 180, ice_lon - 360, ice_lon)\n",
    "    \n",
    "    lon_grid, lat_grid = np.meshgrid(ice_lon, ice_lat)\n",
    "    points = np.array([lon_grid.flatten(), lat_grid.flatten()]).T\n",
    "    values = ice_thick.flatten()\n",
    "    grid_icethick_linear = griddata(points, values, longlat, method='linear')\n",
    "\n",
    "    nan_indices = np.isnan(grid_icethick_linear)\n",
    "    if np.any(nan_indices):\n",
    "      grid_icethick_nearest = griddata(points, values, longlat[nan_indices], method='nearest')\n",
    "      grid_icethick_linear[nan_indices] = grid_icethick_nearest\n",
    "\n",
    "    output_file_path = os.path.join(output_folder_path, f'ice{counter}')  # No extension\n",
    "    np.savetxt(output_file_path, grid_icethick_linear)\n",
    "  \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f06c4f-85f5-4bd3-a3b0-dad783a5430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same method as above\n",
    "\n",
    "times_array = np.array(times_list, dtype=float)\n",
    "times_array = -times_array * 1000\n",
    "\n",
    "times_file_path = os.path.join(output_folder_path, 'times')\n",
    "np.savetxt(times_file_path, times_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5ea32-24de-4c86-a28c-ce0a8b4f2f8e",
   "metadata": {},
   "source": [
    "# PaleoMIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "184bc74c-bb48-4e1e-b01f-7f7cc0156efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same method as above\n",
    "\n",
    "folder_path = 'C:/Users/rubym/OneDrive - Australian National University/Honours/Python Drafts/Non-Interpolated Ice Histories/PaleoMIST_80ka'\n",
    "\n",
    "file_list = sorted(\n",
    "    [f for f in os.listdir(folder_path) if f.startswith(\"ice_thickness_\") and f.endswith(\".grd\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0]) if x.split('_')[-1].split('.')[0].isdigit() else float('inf'),\n",
    "    reverse=True)\n",
    "\n",
    "counter = 1\n",
    "times_list = []\n",
    "\n",
    "output_folder_path = 'C:/Users/rubym/OneDrive - Australian National University/Honours/Python Drafts/Interpolated Ice Histories/PaleoMIST'\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    ice_data = Dataset(file_path)\n",
    "\n",
    "    time = int(file_name.split('_')[-1].split('.')[0])\n",
    "    times_list.append(time)\n",
    "\n",
    "    ice_lat = ice_data['lat'][:]\n",
    "    ice_lon = ice_data['lon'][:]\n",
    "    ice_thick = ice_data['z'][:]\n",
    "    \n",
    "    ice_lon = np.where(ice_lon > 180, ice_lon - 360, ice_lon)\n",
    "    \n",
    "    lon_grid, lat_grid = np.meshgrid(ice_lon, ice_lat)\n",
    "    points = np.array([lon_grid.flatten(), lat_grid.flatten()]).T\n",
    "    values = ice_thick.flatten()\n",
    "    grid_icethick_linear = griddata(points, values, longlat, method='linear')\n",
    "\n",
    "    nan_indices = np.isnan(grid_icethick_linear)\n",
    "    if np.any(nan_indices):\n",
    "      grid_icethick_nearest = griddata(points, values, longlat[nan_indices], method='nearest')\n",
    "      grid_icethick_linear[nan_indices] = grid_icethick_nearest\n",
    "\n",
    "    output_file_path = os.path.join(output_folder_path, f'ice{counter}')  # No extension\n",
    "    np.savetxt(output_file_path, grid_icethick_linear)\n",
    "  \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b2a9379-e2f5-43d4-a18f-e5096c17f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same method as above\n",
    "\n",
    "times_array = np.array(times_list)\n",
    "times_array = -times_array\n",
    "\n",
    "times_file_path = os.path.join(output_folder_path, 'times')\n",
    "np.savetxt(times_file_path, times_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870f014-a064-4c02-bf2f-55ebf9912930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
